{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "matplotlib.rcParams['savefig.dpi'] = 144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import gzip\n",
    "import grader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Data: Predict Temperature\n",
    "Time series prediction presents its own challenges which are different from machine-learning problems.  As with many other classes of problems, there are a number of common features in these predictions.\n",
    "\n",
    "## A note on scoring\n",
    "It **is** possible to score >1 on these questions. This indicates that you've beaten our reference model - we compare our model's score on a test set to your score on a test set. See how high you can go!\n",
    "\n",
    "## Fetch the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!aws s3 sync s3://dataincubator-course/mldata/ . --exclude '*' --include 'train.txt.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns of the data correspond to the\n",
    "  - year\n",
    "  - month\n",
    "  - day\n",
    "  - hour\n",
    "  - temp\n",
    "  - dew_temp\n",
    "  - pressure\n",
    "  - wind_angle\n",
    "  - wind_speed\n",
    "  - sky_code\n",
    "  - rain_hour\n",
    "  - rain_6hour\n",
    "  - city\n",
    "\n",
    "This function will read the data from a file handle into a Pandas DataFrame.  Feel free to use it, or to write your own version to load it in the format you desire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_stream(stream):\n",
    "    return pd.read_table(stream, sep=' *', engine='python',\n",
    "                         names=['year', 'month', 'day', 'hour', 'temp',\n",
    "                                'dew_temp', 'pressure', 'wind_angle', \n",
    "                                'wind_speed', 'sky_code', 'rain_hour',\n",
    "                                'rain_6hour', 'city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_stream(gzip.open('train.txt.gz', 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The temperature is reported in tenths of a degree Celcius.  However, not all the values are valid.  Examine the data, and remove the invalid rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will focus on using the temporal elements to predict the temperature.\n",
    "\n",
    "## Per city model\n",
    "\n",
    "It makes sense for each city to have it's own model.  Build a \"groupby\" estimator that takes an estimator factory as an argument and builds the resulting \"groupby\" estimator on each city.  That is, `fit` should create and fit a model per city, while the `predict` method should look up the corresponding model and perform a predict on each.  An estimator factory is something that returns an estimator each time it is called.  It could be a function or a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import base\n",
    "\n",
    "class GroupbyEstimator(base.BaseEstimator, base.RegressorMixin):\n",
    "    \n",
    "    def __init__(self, column, features, estimator_factory):\n",
    "        self.column = column\n",
    "        self.features = features\n",
    "        self.estimator_factory = estimator_factory\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        groups = list(X[self.column].unique())\n",
    "        self.fit_dict = {}\n",
    "        for ii in groups:\n",
    "            mask = X[self.column] == ii\n",
    "            x_tmp = X[mask][self.features].values\n",
    "            y_tmp = y[mask]   \n",
    "            self.fit_dict[ii] = self.estimator_factory.fit(x_tmp,y_tmp)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = [x.split() for x in X]\n",
    "        X = pd.DataFrame(X)\n",
    "        X.columns = ['year', 'month', 'day', 'hour', 'temp',\n",
    "                                'dew_temp', 'pressure', 'wind_angle', \n",
    "                                'wind_speed', 'sky_code', 'rain_hour',\n",
    "                                'rain_6hour', 'city']\n",
    "        \n",
    "        # print X\n",
    "        return X.apply(lambda x: self.fit_dict[x['city']].predict(x[self.features].values.reshape(1,-1)), 1)['temp'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "\n",
    "For each question, build a model to predict the temperature in a given city at a given time.  You will be given a list of records, each a string in the same format as the lines in the training file.  Return a list of predicted temperatures, one for each incoming record.  (As you can imagine, the temperature values will be stripped out in the actual text records.)\n",
    "\n",
    "## month_hour_model\n",
    "Seasonal features are nice because they are relatively safe to extrapolate into the future. There are two ways to handle seasonality.  \n",
    "\n",
    "The simplest (and perhaps most robust) is to have a set of indicator variables. That is, make the assumption that the temperature at any given time is a function of only the month of the year and the hour of the day, and use that to predict the temperature value.\n",
    "\n",
    "**Question**: Should month be a continuous or categorical variable?  (Recall that [one-hot encoding](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) is useful to deal with categorical variables.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xgbr = xgb.XGBRegressor(max_depth=5, learning_rate=0.1,colsample_bytree=0.7, subsample=0.7,n_estimators=100,\n",
    "                   reg_alpha = 0.1, reg_lambda = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.replace(-9999, np.nan)\n",
    "df = df.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def season_factory():\n",
    "    return xgbr\n",
    "\n",
    "features = ['month', 'day', 'hour', 'pressure', 'wind_speed','wind_angle', 'sky_code', 'rain_hour', 'rain_6hour']\n",
    "\n",
    "season_model = GroupbyEstimator('city', features, xgbr).fit(df, df['temp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to write a function that makes predictions from a list of strings.  You can either create a pipeline with a transformer and the `season_model`, or you can write a helper function to convert the lines to the format you expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================\n",
      "Your score:  1.10612415472\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "grader.score('ts__month_hour_model', season_model.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright &copy; 2016 The Data Incubator.  All rights reserved.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "nbclean": true
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
